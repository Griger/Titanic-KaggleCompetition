---
title: "Realizando el tutorial de Megan Risdal"
author: "Gustavo Rivas Gervilla"
date: "2 de abril de 2017"
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduccion

Lo que vamos a hacer a continuación es, a modo de introducción tanto al dataset como al uso de la plataforma Kaggle, es seguir el [tutorial](https://www.kaggle.com/mrisdal/titanic/exploring-survival-on-the-titanic) eleborado por Megan Risdal. En primer lugar lo que hacemos es cargar los paquetes que serán necesarios a lo largo de este tutorial:

```{r, message=FALSE}
library(ggplot2) #visualizacion
library(ggthemes) #visualizacion
library(scales) #visualizacion
library(dplyr) #manipulacion de datos
library(mice) # imputacion (valores perdidos)
library(randomForest) # el algoritmo de clasificacion que emplearemos en este tutorial
```

Una vez hecho esto pasamos a cargar los datasets, tanto el de train como el de test, estos los hemos descargado previamente de la [página de Kaggle](https://www.kaggle.com/c/titanic/data) de la competición:

```{r}
train <- read.csv('data/train.csv', stringsAsFactors = FALSE)
test <- read.csv('data/test.csv', stringsAsFactors = FALSE)

#formamos un unico dataset con todas las instancias
full <- bind_rows(train, test)
```

Lo que hemos hecho con el método `bind_rows` del paquete **dplyr** es combinar los dos datasets en uno sólo. Podemos pensar en que para este propósito nos valdría con emplear el método `rbind`, el problema es que el conjunto de test no dispone (como es de esperar) de la columna *Survived* y en ese caso este método nos daría un error. En cambio usando `bind_rows` los unimos sin problemas ya que el propio método se encarga de añadir el valor **NA** en aquellos valores que sean necesarios para unir ambos datasets, en este caso el atributo a predecir.

TODO: añadir la descripción del dataset, ya escrita en el portátil.

# Ingeniería de características

Vamos ahora a trabajar con los datos de los que disponemos para tratar de prepararlos de modo que sean más útiles de cara a un futuro modelo de clasificación que queramos emplear. Si empleamos el método `View` sobre el dataset `full` el nombre de cada pasejero viene acompañado de un título, como puede ser *Mr.* o *Miss*. Lo que se pretende con el siguiente código es extraer estos títulos a una nueva columna. El nombre del pasajero en un principio no parece ser algo determinante para que el pasajero muera o sobrevida (aunque en caso de que, en un escenario tan caótico con la evacuación de los pasajeros en una naufragio, los pajeros fuesen evacuados por orden alfabético, el nombre si podría ser una buena fuente de información), en cambio el título del mismo y por tanto la clase social del pasajero sí que podría aportarnos una información importante de cara a la predicción.

```{r}
full$Title <- gsub('(.*, )|(\\..*)', '', full$Name)

table(full$Sex, full$Title)
```

Lo que hacemos con el método `gsub` es para cada nombre cambiar lo que hay tras un punto o similar por la cadena vacía, con lo que así sólo nos quedamos con el título del pasajero.

En la tabla anterior se muestra la distribución de los distintos títulos que extraemos de los nombres de todos los pasajeros por género. Así podemos ver por ejemplo que el capitán era un hombre. Además vemos que hay títulos que son poco frecuentes así que vamos a agrupar todos estos títulos en una sola categoría.

La razón para hacer lo anterior puede deberse a que no queremos que el clasificador tenga que tener en cuenta una granularidad tan alta en el título del pasajero cuando realmente, si es un título que se da tampoco, no nos va a dar un gran poder de discriminación, ya que la mayoría de las instancias no tendrán dicho título. También vamos a agrupar algunos títulos que son equivalentes y que por tanto no se espera que haya una diferencia entre las instancias con un título y uno equivalente:

```{r}
rare_title <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don', 
                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')

full$Title[full$Title == 'Mlle']        <- 'Miss' 
full$Title[full$Title == 'Ms']          <- 'Miss'
full$Title[full$Title == 'Mme']         <- 'Mrs' 
full$Title[full$Title %in% rare_title]  <- 'Rare Title'
```

Señalar que al contrario de lo que yo pensaba *Mrs* y *Miss* son títulos distintos; mientras que el primero se aplica a mujeres casadas, el segundo se aplica a mujeres solteras, por esto se establece esta distincción que puede resultar confusa, al menos a mí me lo ha parecido en un principio.

Ahora vamos a tratar de comprobar si las familias a bordo del Titanic fueron evacuadas en grupo o si no se tuvo en cuenta el parentesco para evacuar a los pasajeros. Para ello lo primero que hacemos es extraer el apellido del pasajero de su nombre:

```{r}
full$Surname <- sapply(full$Name, function(x) strsplit(x, split = '[,.]')[[1]][1])
```

Lo que vamos hacer a continuación es añadirle a cada pasajero el número de familiares que tiene a bordo, contándole a él, de este modo podremos ver el tamaño de las familias que viajaban a bordo del Titanic y si esto es un factor que afecte a la probabilidad de sobrevivencia de un pasajero. También fabricaremos una nueva variable donde se unirán el apellido del pasajero junto a este número de familiares a bordo.

```{r}
full$Fsize <- full$SibSp + full$Parch + 1
full$Family <- paste(full$Surname, full$Fsize, sep='_')
```

Y ahora vamos a ver cómo se distribuye la tasa de sobrevivientes y muertos según el número de familiares que fuesen a bordo:

```{r}
ggplot(full[1:891,], aes(x = Fsize, fill = factor(Survived))) +
  geom_bar(stat='count', position='dodge') +
  scale_x_continuous(breaks=c(1:11)) +
  labs(x = 'Tamaño de la familia', y = "conteo") +
  theme_few()
```

Aquí podemos apreciar algo interesantes y es que por un lado aquellos que viajaban solos tenían más posibilidades de morir, por otro lado, cuando el tamaño de las familias pasa de 4 entonces el número de muertes es mayor que el de vivos. Por lo tanto aquí observamos que se intentaba que las familias fuesen evacuadas juntas pero que cuando la familia era de un tamaño mayor entonces esto era más difícil; al menos esto podemos interpretar de la gráfica anterior. A la luz de este análisis vamos a establecer 3 tipos de pasajeros: aquellos que viajaban solos, los que iban con una familia de tamaño reducido (como mucho 4 familiares) y los que embarcaron con una familia numerosa:

```{r}
full$FsizeD[full$Fsize == 1] <- 'singleton'
full$FsizeD[full$Fsize < 5 & full$Fsize > 1] <- 'small'
full$FsizeD[full$Fsize > 4] <- 'large'

mosaicplot(table(full$FsizeD, full$Survived), main='Proporción de sobrevivientes por tamaño', shade=TRUE)
```

Y en la gráfica anterior lo que vemos es que efectivamente era mayor la probabilidad de sobrevivir para los individuos que viajaban con su familia pero siempre que esta familia fuese de un tamaño reducido.

Aunque tenemos valores perdidos de los que nos vamos a ocupar en la próxima sección, lo que vamos a hacer es construir una nueva variable en la que se extrae la cubierta en la cual esta embarcado el pasajero. Esto lo vamos a extraer del camarote de cada pasejero por medio del siguiente código, que lo único que hace es separar cada cadena en los caracteres que la forman y quedarse con el primero; la letra que designa la cubierta:

```{r}
full$Deck<-factor(sapply(full$Cabin, function(x) strsplit(x, NULL)[[1]][1]))
```

# Valores perdidos

En primer lugar se observa que los pasajeros 62 y 830 no tienen información en el atributo que nos informa desde qué puerto se embarcaron los pasajeros, así que lo que se va a hacer es tratar de deducirlo a partir de otros datos que sí tenemos del pasajero. Señalar que a continuación se va a emplear información de todo el dataset incluido los datos de test, esto es algo del todo adecuado ya que teóricamente no se dispone del conjunto de test durante el entrenamiento. No obstante a modo de entrenamiento lo haremos así. Vamos a deducir el puerto desde el que embarcaron los pasajeros a partir de lo que pagaron por su billete y la clase de su pasaje que coincide en ambos (80$ en primera clase):

```{r}
embark_fare <- full %>%
  filter(PassengerId != 62 & PassengerId != 830)

# Use ggplot2 to visualize embarkment, passenger class, & median fare
ggplot(embark_fare, aes(x = Embarked, y = Fare, fill = factor(Pclass))) +
  geom_boxplot() +
  geom_hline(aes(yintercept=80), 
    colour='red', linetype='dashed', lwd=2) +
  scale_y_continuous(labels=dollar_format()) +
  theme_few()
```

Y lo que vemos en la siguiente gráfica que nos muestra por puerto de embarque y clase de pasaje cómo se distribuye la tarifa pagada, es que la tarifa media para un pasajero de primera clase que embarcase desde el puerto C está muy próxima a los 80$ que pagaron los dos pasajeros, con lo cual lo que vamos a hacer es asociarle este puerto de embarque a ambos:

```{r}
full$Embarked[c(62, 830)] <- 'C'
```

Hay otro pasajero, el 1044, que tiene como valor perdido (además de si sobrevivió o no, ya que es una instancia del dataset de test) la tarifa que pagó. Entonces vamos a tratar de deducirla a partir de los datos que tenemos. Este pasajero compró un billete de tercera clase desde el puerto S, con lo cual vamos a ver qué pagaron otros pasajeros con las mismas características (podríamos pensar también en trabajar con la edad del pasajero pero en esta ocasión esto no se ha tenido en cuenta):

```{r}
ggplot(full[full$Pclass == '3' & full$Embarked == 'S', ], 
  aes(x = Fare)) +
  geom_density(fill = '#99d6ff', alpha=0.4) + 
  geom_vline(aes(xintercept=median(Fare, na.rm=T)),
    colour='red', linetype='dashed', lwd=1) +
  scale_x_continuous(labels=dollar_format()) +
  theme_few()
```

A partir de esta gráfica vemos que asignarle como tarifa la media de lo que pagaron el resto de pasajeros con las mismas características no parece una mala aproximación, hay un gran concentración de instancias al rededor de la media:

```{r}
full$Fare[1044] <- median(full[full$Pclass == '3' & full$Embarked == 'S', ]$Fare, na.rm = TRUE)
```

Antes de continuar vamos a ver cómo se distribuyen los valores perdidos que quedan en el dataset:

```{r}
apply(full, 2, function(x) sum(is.na(x)))
```

Aquí lo que vemos es que los valores perdidos que nos quedan están en la de los pasajeros y en la cubierta, esto último no es cierto, lo que ocurre es que realmente hay muchos pasajeros en los que no está especificado el camarote en el que estuvo el pasajero. Lo que vamos a hacer es imputar estos valores usando un modelo predictivo, para ello vamos a usar el paquete `mice`. Pero antes vamos a pasar a factor las variables que son de esta naturaleza y que en el dataset no están recogidas de esta forma:

```{r}
factor_vars <- c('PassengerId','Pclass','Sex','Embarked','Title','Surname','Family','FsizeD')
full[factor_vars] <- lapply(full[factor_vars], function(x) as.factor(x))
```

```{r, message=FALSE}
set.seed(129)
mice_mod <- mice(full[, !names(full) %in% c('PassengerId','Name','Ticket','Cabin','Family','Surname','Survived')], method='rf') 
```

Aquí se están imputando todas las dos variables que presentan valores perdidos que ya hemos mencionado usando partición recursiva para regresión (la edad se puede considerar un atributo continuo al tener tanta granularidad en sus valores), la expresión lógica que empleamos es para que no se use en el modelo predictivo aquellas variables que no consideramos útiles para tal propósito. Vamos a ver a continuación la distribución de edades en el dataset original y en el devuelto por `mice` para ver que tienen cierta consonancia y que la imputación no ha distorsionado los datos:

```{r}
mice_output <- complete(mice_mod)

par(mfrow=c(1,2))
hist(full$Age, freq=F, main='Age: Original Data', 
  col='darkgreen', ylim=c(0,0.04))
hist(mice_output$Age, freq=F, main='Age: MICE Output', 
  col='lightgreen', ylim=c(0,0.04))
```

Como vemos que las distribuciones son similares damos por buena la imputación obtenida y pasamos a sustituir los valores perdidos por los predichos con `mice`:

```{r}
full$Age <- mice_output$Age
```

# Algo más de ingeniería de características

Vamos a ver cómo se distribuye para cada sexo la tasa de sobreviviente según la edad; ahora que tenemos todas las instancias con una edad asignada podemos hacer este tipo de estudios para el dataset completo sin dejar fuera aquellas instancias que no presentaban edad:

```{r}
ggplot(full[1:891,], aes(Age, fill = factor(Survived))) + 
  geom_histogram() +
  facet_grid(.~Sex) + 
  theme_few()
```

Aquí lo que podemos apreciar es en primer lugar que las mujeres sobreviven en mayor proporción que los hombres, por otro lado los hombres jóvenes parecen sobrevivir en mayor proporción que los mayores, al contrario que ocurre con las mujeres.

Vamos a crear dos nuevas variables, una que nos indica si el pasajero es un niño, considerando como niño una persona menor que 18 años (nuestro compañero Jose Ángel Díaz mejoró los resultados considerando niño aquel que tuviese menos de 16 años ya que pensó que en aquella época se consideraba adulto antes a una persona, estudiaremos esto más adelante). La otra nos indica si el pasajero es madre, para ello vemos si es una mujer por encima de los 18 años y con al menos un hijo:

```{r}
full$Child[full$Age < 18] <- 'Child'
full$Child[full$Age >= 18] <- 'Adult'

full$Mother <- 'Not Mother'
full$Mother[full$Sex == 'female' & full$Parch > 0 & full$Age > 18 & full$Title != 'Miss'] <- 'Mother'

full$Child  <- factor(full$Child)
full$Mother <- factor(full$Mother)
```

# Finalmente hacemos predicción

```{r}
train <- full[1:891,]
test <- full[892:1309,]

rf_model <- randomForest(factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + 
                                            Fare + Embarked + Title + 
                                            FsizeD + Child + Mother,
                                            data = train)

plot(rf_model, ylim=c(0,0.36))
legend('topright', colnames(rf_model$err.rate), col=1:3, fill=1:3)
```

En la gráfica anterior podemos ver el error medio, el error en los positivos y el error en los negativos según aumenta el número de árboles empleados en la predicción. Vamos a ver ahora la importancia de cada una de las variables en la creación del modelo:

```{r}
importance    <- importance(rf_model)
varImportance <- data.frame(Variables = row.names(importance), 
                            Importance = round(importance[ ,'MeanDecreaseGini'],2))

rankImportance <- varImportance %>% mutate(Rank = paste0('#',dense_rank(desc(Importance))))

ggplot(rankImportance, aes(x = reorder(Variables, Importance), 
    y = Importance, fill = Importance)) +
  geom_bar(stat='identity') + 
  geom_text(aes(x = Variables, y = 0.5, label = Rank),
    hjust=0, vjust=0.55, size = 4, colour = 'red') +
  labs(x = 'Variables') +
  coord_flip() + 
  theme_few()
```

Como vemos las variables con más importancia son el título del pasajero, la tarifa que pagó, su sexo y la edad. Finalmente hacemos nuestra predicción:

```{r}
prediction <- predict(rf_model, test)
solution <- data.frame(PassengerID = test$PassengerId, Survived = prediction)
write.csv(solution, file = 'sols/RiscalSol.csv', row.names = F, quote = F)
```

A continuación se muestra el código empleado para generar una predicción completamente aleatoria:

```{r, eval=FALSE}
randomPrediction = sample(c(0,1), nrow(test), replace = T)
randomSolution <- data.frame(PassengerID = test$PassengerId, Survived = randomPrediction)
write.csv(randomSolution, file = 'sols/randomSol.csv', row.names = F, quote = F)
```